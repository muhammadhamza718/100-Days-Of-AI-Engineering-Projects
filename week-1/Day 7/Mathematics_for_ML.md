# Day 7: Mathematics for Machine Learning

## Overview

Welcome to Day 7 of your AI Engineering journey! Today, we build the **mathematical foundation** essential for understanding and implementing machine learning algorithms. You'll master the core concepts from **Linear Algebra**, **Calculus**, and **Probability & Statistics** that power modern ML. By the end, you'll understand gradient descent, the optimization algorithm at the heart of neural networks.

## Tech Stack

- **Language:** Python 3.x
- **Core Libraries:** NumPy
- **Visualization:** Matplotlib
- **Package Manager:** uv

---

## 1. Linear Algebra Review

Linear algebra is the language of machine learning. Vectors represent data points, matrices represent datasets, and transformations represent models.

### 1.1 Vectors

**Definition:** A vector is an ordered array of numbers representing magnitude and direction.

**Vector Operations:**

- **Addition:** Element-wise addition of corresponding components
  - vâ‚ + vâ‚‚ = [vâ‚â‚ + vâ‚‚â‚, vâ‚â‚‚ + vâ‚‚â‚‚, ..., vâ‚â‚™ + vâ‚‚â‚™]
- **Scalar Multiplication:** Multiply each component by a scalar
  - c Â· v = [cÂ·vâ‚, cÂ·vâ‚‚, ..., cÂ·vâ‚™]
- **Dot Product:** Sum of element-wise products
  - vâ‚ Â· vâ‚‚ = vâ‚â‚Â·vâ‚‚â‚ + vâ‚â‚‚Â·vâ‚‚â‚‚ + ... + vâ‚â‚™Â·vâ‚‚â‚™
  - Geometric interpretation: vâ‚ Â· vâ‚‚ = |vâ‚| |vâ‚‚| cos(Î¸)
- **Magnitude (L2 Norm):** Length of a vector
  - |v| = âˆš(vâ‚Â² + vâ‚‚Â² + ... + vâ‚™Â²)
- **Unit Vector:** Vector with magnitude 1
  - vÌ‚ = v / |v|

**Key Concepts:**

- **Dot Product:** Measures similarity between vectors (high = similar direction, zero = orthogonal)
- **Norm:** Represents the length/magnitude of a vector
- **Orthogonal Vectors:** Two vectors are orthogonal if their dot product equals zero (they are perpendicular)
- **Vector Space:** A collection of vectors that can be added together and multiplied by scalars

**Applications in ML:**

- Feature vectors represent data samples
- Similarity measures (cosine similarity uses dot product)
- Distance metrics (Euclidean distance uses L2 norm)

### 1.2 Matrices

**Definition:** A matrix is a 2D rectangular array of numbers arranged in rows and columns. In ML, each row often represents a data sample, and each column represents a feature.

**Matrix Notation:**

- A matrix A of size mÃ—n has m rows and n columns
- Element at row i, column j is denoted as Aáµ¢â±¼

**Matrix Operations:**

1. **Transpose (Aáµ€):** Flip rows and columns

   - If A is mÃ—n, then Aáµ€ is nÃ—m
   - (Aáµ€)áµ¢â±¼ = Aâ±¼áµ¢

2. **Matrix Addition:** Add corresponding elements (requires same dimensions)

   - C = A + B where Cáµ¢â±¼ = Aáµ¢â±¼ + Báµ¢â±¼

3. **Scalar Multiplication:** Multiply every element by a scalar

   - C = cÂ·A where Cáµ¢â±¼ = cÂ·Aáµ¢â±¼

4. **Matrix Multiplication:** Combine two matrices
   - For A (mÃ—n) and B (nÃ—p), result C is (mÃ—p)
   - Cáµ¢â±¼ = Î£â‚– Aáµ¢â‚– Â· Bâ‚–â±¼ (dot product of row i of A and column j of B)
   - **NOT commutative:** AÂ·B â‰  BÂ·A (in general)
   - **Associative:** (AÂ·B)Â·C = AÂ·(BÂ·C)

**Matrix Multiplication Rules:**

- Inner dimensions must match: (mÃ—n)Â·(nÃ—p) = (mÃ—p)
- Element (i,j) = dot product of A's row i with B's column j
- Represents composition of linear transformations

### 1.3 Special Matrices

**Identity Matrix (I):**

- Square matrix with 1s on diagonal, 0s elsewhere
- Property: AÂ·I = IÂ·A = A
- Acts as the "multiplication identity" for matrices

**Inverse Matrix (Aâ»Â¹):**

- Matrix that "undoes" A: AÂ·Aâ»Â¹ = Aâ»Â¹Â·A = I
- Only exists for square, non-singular matrices
- If det(A) â‰  0, then A is invertible

**Determinant (det(A)):**

- Scalar value that encodes certain properties of the matrix
- If det(A) = 0, matrix is singular (not invertible)
- Represents the scaling factor of the transformation
- For 2Ã—2 matrix: det([[a,b],[c,d]]) = ad - bc

**Symmetric Matrix:**

- A = Aáµ€ (equals its own transpose)
- Important in optimization (Hessian matrices)

**Diagonal Matrix:**

- All non-diagonal elements are zero
- Efficient for computation

### 1.4 Eigenvalues and Eigenvectors

**Definition:** For a square matrix A, eigenvector **v** and eigenvalue **Î»** satisfy:

**AÂ·v = Î»Â·v**

This means applying transformation A to v only scales it by Î», without changing its direction.

**Properties:**

- A has n eigenvalues (counting multiplicities) if it's nÃ—n
- Eigenvectors corresponding to different eigenvalues are linearly independent
- For symmetric matrices, eigenvectors are orthogonal

**Eigenvalue Decomposition:**

- A = QÂ·Î›Â·Qâ»Â¹
- Where Q contains eigenvectors as columns
- Î› is a diagonal matrix of eigenvalues

**Applications in ML:**

1. **Principal Component Analysis (PCA):**

   - Finds directions (eigenvectors) of maximum variance in data
   - Eigenvalues indicate the importance of each direction
   - Used for dimensionality reduction

2. **Spectral Clustering:**

   - Uses eigenvectors of similarity matrices
   - Reveals underlying cluster structure

3. **Stability Analysis:**

   - Eigenvalues determine if a system is stable
   - Used in analyzing neural network dynamics

4. **Matrix Powers:**
   - Computing Aâ¿ efficiently using eigendecomposition

---

## 2. Calculus Basics

Calculus enables us to optimize functions, which is the core of training machine learning models.

### 2.1 Derivatives

**Definition:** The derivative f'(x) measures the instantaneous rate of change of function f at point x.

**Geometric Interpretation:**

- Derivative = slope of the tangent line at a point
- Positive derivative â†’ function is increasing
- Negative derivative â†’ function is decreasing
- Zero derivative â†’ potential local minimum/maximum

**Fundamental Derivative Rules:**

1. **Power Rule:**

   - d/dx(xâ¿) = nÂ·xâ¿â»Â¹

2. **Constant Rule:**

   - d/dx(c) = 0

3. **Sum Rule:**

   - d/dx(f + g) = f' + g'

4. **Product Rule:**

   - d/dx(fÂ·g) = f'Â·g + fÂ·g'

5. **Quotient Rule:**

   - d/dx(f/g) = (f'Â·g - fÂ·g') / gÂ²

6. **Chain Rule:**
   - d/dx(f(g(x))) = f'(g(x))Â·g'(x)

**Common Derivatives:**

- d/dx(eË£) = eË£
- d/dx(ln(x)) = 1/x
- d/dx(sin(x)) = cos(x)
- d/dx(cos(x)) = -sin(x)

**Applications in ML:**

- Computing gradients for optimization
- Backpropagation in neural networks
- Finding optimal parameters

### 2.2 Partial Derivatives

**Definition:** For functions with multiple variables f(xâ‚, xâ‚‚, ..., xâ‚™), a partial derivative measures the rate of change with respect to one variable while holding all others constant.

**Notation:**

- âˆ‚f/âˆ‚xâ‚ = partial derivative with respect to xâ‚
- âˆ‚f/âˆ‚xâ‚‚ = partial derivative with respect to xâ‚‚

**Example:**
For f(x, y) = xÂ² + 2xy + yÂ²:

- âˆ‚f/âˆ‚x = 2x + 2y (treat y as constant)
- âˆ‚f/âˆ‚y = 2x + 2y (treat x as constant)

**Higher-Order Derivatives:**

- âˆ‚Â²f/âˆ‚xÂ² = second partial derivative (curvature)
- âˆ‚Â²f/âˆ‚xâˆ‚y = mixed partial derivative
- Hessian matrix: contains all second-order partial derivatives

### 2.3 Gradients

**Definition:** The gradient âˆ‡f is a vector of all partial derivatives:

**âˆ‡f = [âˆ‚f/âˆ‚xâ‚, âˆ‚f/âˆ‚xâ‚‚, ..., âˆ‚f/âˆ‚xâ‚™]**

**Key Properties:**

1. **Direction:** Points in the direction of steepest ascent
2. **Magnitude:** Indicates how steep the ascent is
3. **Perpendicular to level curves:** Always perpendicular to contour lines of constant f

**Gradient Descent:**

- To minimize f, move in the **opposite** direction of the gradient
- Update rule: x_new = x_old - Î±Â·âˆ‡f(x_old)
- Î± is the learning rate (step size)

**Directional Derivative:**

- Rate of change in direction of unit vector u
- D_u f = âˆ‡f Â· u
- Maximum when u is parallel to âˆ‡f

**Applications:**

- Optimization algorithms (gradient descent, Adam, etc.)
- Backpropagation in deep learning
- Finding critical points (where âˆ‡f = 0)

### 2.4 Taylor Series

**Definition:** Approximation of a function using polynomials:

**f(x) â‰ˆ f(a) + f'(a)(x-a) + f''(a)(x-a)Â²/2! + ...**

**First-order (Linear) Approximation:**

- f(x) â‰ˆ f(a) + âˆ‡f(a)Â·(x-a)
- Used in gradient descent

**Second-order (Quadratic) Approximation:**

- f(x) â‰ˆ f(a) + âˆ‡f(a)Â·(x-a) + Â½(x-a)áµ€H(a)(x-a)
- H is the Hessian matrix
- Used in Newton's method

---

## 3. Probability and Statistics Fundamentals

Understanding uncertainty is crucial for machine learning, especially for probabilistic models and evaluation metrics.

### 3.1 Probability Basics

**Sample Space (S):** Set of all possible outcomes

**Event:** A subset of the sample space

**Probability Axioms:**

1. 0 â‰¤ P(A) â‰¤ 1 for any event A
2. P(S) = 1 (something must happen)
3. For mutually exclusive events: P(A âˆª B) = P(A) + P(B)

**Key Probability Rules:**

1. **Addition Rule:**

   - P(A âˆª B) = P(A) + P(B) - P(A âˆ© B)

2. **Multiplication Rule (Independent Events):**

   - P(A âˆ© B) = P(A) Ã— P(B)

3. **Conditional Probability:**

   - P(A|B) = P(A âˆ© B) / P(B)
   - Read as "probability of A given B"

4. **Bayes' Theorem:**
   - P(A|B) = P(B|A) Ã— P(A) / P(B)
   - Fundamental for Bayesian inference and machine learning

**Law of Total Probability:**

- P(B) = Î£áµ¢ P(B|Aáµ¢) Ã— P(Aáµ¢)

### 3.2 Random Variables

**Definition:** A random variable is a function that assigns a numerical value to each outcome in a sample space.

**Types:**

1. **Discrete:** Takes countable values (e.g., coin flips, dice rolls)
2. **Continuous:** Takes any value in a range (e.g., height, temperature)

**Probability Mass Function (PMF):** For discrete variables

- P(X = x) = probability that X equals x
- Î£ P(X = x) = 1 (over all possible x)

**Probability Density Function (PDF):** For continuous variables

- f(x) â‰¥ 0 for all x
- âˆ« f(x)dx = 1 (over entire range)
- P(a â‰¤ X â‰¤ b) = âˆ«â‚áµ‡ f(x)dx

**Cumulative Distribution Function (CDF):**

- F(x) = P(X â‰¤ x)
- Monotonically increasing
- lim(xâ†’-âˆ) F(x) = 0, lim(xâ†’âˆ) F(x) = 1

### 3.3 Common Probability Distributions

**1. Normal (Gaussian) Distribution:**

- PDF: f(x) = (1/âˆš(2Ï€ÏƒÂ²)) exp(-(x-Î¼)Â²/(2ÏƒÂ²))
- Parameters: Î¼ (mean), ÏƒÂ² (variance)
- Notation: N(Î¼, ÏƒÂ²)
- 68-95-99.7 Rule: 68% within 1Ïƒ, 95% within 2Ïƒ, 99.7% within 3Ïƒ
- Central Limit Theorem: Sum of many random variables â†’ normal

**2. Binomial Distribution:**

- Models number of successes in n independent trials
- P(X = k) = C(n,k) páµ (1-p)â¿â»áµ
- Parameters: n (trials), p (success probability)
- Mean: np, Variance: np(1-p)

**3. Uniform Distribution:**

- All outcomes equally likely
- PDF: f(x) = 1/(b-a) for x âˆˆ [a,b]
- Mean: (a+b)/2

**4. Exponential Distribution:**

- Models time between events
- PDF: f(x) = Î»eâ»áµË£ for x â‰¥ 0
- Mean: 1/Î», Variance: 1/Î»Â²

### 3.4 Expected Value and Variance

**Expected Value (Mean):**

- E[X] = Î¼ = Î£ xÂ·P(X=x) for discrete
- E[X] = âˆ« xÂ·f(x)dx for continuous
- Represents the "average" or "center" of the distribution

**Properties:**

- E[aX + b] = aE[X] + b (linearity)
- E[X + Y] = E[X] + E[Y]

**Variance:**

- Var(X) = ÏƒÂ² = E[(X - Î¼)Â²] = E[XÂ²] - (E[X])Â²
- Measures spread/dispersion around the mean

**Standard Deviation:**

- Ïƒ = âˆšVar(X)
- Same units as the original variable

**Properties:**

- Var(aX + b) = aÂ²Var(X)
- For independent X, Y: Var(X + Y) = Var(X) + Var(Y)

### 3.5 Covariance and Correlation

**Covariance:**

- Cov(X, Y) = E[(X - E[X])(Y - E[Y])]
- Measures how two variables change together
- Positive: tend to increase together
- Negative: one increases when other decreases
- Zero: no linear relationship

**Correlation Coefficient:**

- Ï(X, Y) = Cov(X, Y) / (Ïƒâ‚“ Â· Ïƒáµ§)
- Normalized covariance: -1 â‰¤ Ï â‰¤ 1
- Ï = 1: perfect positive linear relationship
- Ï = -1: perfect negative linear relationship
- Ï = 0: no linear relationship

**Important:** Correlation â‰  Causation!

### 3.6 Statistical Measures

**Central Tendency:**

1. **Mean:** Average value = Î£xáµ¢ / n
2. **Median:** Middle value when sorted
3. **Mode:** Most frequent value

**Spread:**

1. **Range:** Maximum - Minimum
2. **Interquartile Range (IQR):** Qâ‚ƒ - Qâ‚
3. **Variance:** Average squared deviation from mean
4. **Standard Deviation:** Square root of variance

**Shape:**

1. **Skewness:** Measure of asymmetry
   - Positive skew: tail on right
   - Negative skew: tail on left
2. **Kurtosis:** Measure of "tailedness"
   - High kurtosis: heavy tails, more outliers

**Percentiles/Quantiles:**

- Qâ‚–: Value below which k% of data falls
- Qâ‚ (25th), Qâ‚‚ (50th = median), Qâ‚ƒ (75th)

---

## 4. Gradient Descent: Theory

**Gradient Descent** is the fundamental optimization algorithm for training machine learning models.

### 4.1 The Optimization Problem

**Goal:** Find x\* that minimizes f(x)

- x\* = arg min f(x)

**Approach:** Start at some point and iteratively move toward the minimum

### 4.2 Gradient Descent Algorithm

**Core Idea:** Move in the direction opposite to the gradient (steepest descent)

**Update Rule:**
**xâ‚œâ‚Šâ‚ = xâ‚œ - Î±Â·âˆ‡f(xâ‚œ)**

Where:

- xâ‚œ = current position at iteration t
- Î± = learning rate (step size)
- âˆ‡f(xâ‚œ) = gradient at current position
- xâ‚œâ‚Šâ‚ = new position

**Algorithm Steps:**

1. Initialize xâ‚€ (starting point)
2. Compute gradient âˆ‡f(xâ‚œ)
3. Update: xâ‚œâ‚Šâ‚ = xâ‚œ - Î±Â·âˆ‡f(xâ‚œ)
4. Repeat until convergence

### 4.3 Convergence Criteria

**When to stop:**

1. **Gradient magnitude:** |âˆ‡f(x)| < Îµ (very small)
2. **Function change:** |f(xâ‚œâ‚Šâ‚) - f(xâ‚œ)| < Îµ
3. **Parameter change:** |xâ‚œâ‚Šâ‚ - xâ‚œ| < Îµ
4. **Maximum iterations:** Fixed number of steps

### 4.4 Learning Rate (Î±)

**Critical Hyperparameter:**

1. **Too Small (Î± â†’ 0):**

   - âœ… Stable convergence
   - âŒ Very slow, many iterations needed
   - âŒ May get stuck in plateaus

2. **Too Large (Î± â†’ âˆ):**

   - âŒ Unstable, may diverge
   - âŒ Oscillates around minimum
   - âŒ May overshoot optimal point

3. **Optimal (Goldilocks Î±):**
   - âœ… Fast convergence
   - âœ… Stable updates
   - âœ… Reaches minimum efficiently

**Learning Rate Schedules:**

- **Constant:** Î± stays same
- **Time-based decay:** Î± = Î±â‚€ / (1 + kt)
- **Step decay:** Reduce Î± every k iterations
- **Exponential decay:** Î± = Î±â‚€ Â· eâ»áµáµ—
- **Adaptive:** Different Î± for each parameter (Adam, RMSprop)

### 4.5 Types of Gradient Descent

**1. Batch Gradient Descent:**

- Uses entire dataset to compute gradient
- âˆ‡f = (1/N) Î£áµ¢ âˆ‡L(xáµ¢)
- âœ… Accurate gradient
- âŒ Slow for large datasets
- âŒ High memory requirements

**2. Stochastic Gradient Descent (SGD):**

- Uses one random sample at a time
- âˆ‡f â‰ˆ âˆ‡L(xáµ¢) for random i
- âœ… Fast updates
- âœ… Can escape local minima
- âŒ Noisy, high variance
- âŒ May not converge exactly

**3. Mini-batch Gradient Descent:**

- Uses small batches (e.g., 32, 64, 128 samples)
- âˆ‡f â‰ˆ (1/B) Î£áµ¢â‚Œâ‚á´® âˆ‡L(xáµ¢)
- âœ… Balance between accuracy and speed
- âœ… Efficient GPU utilization
- âœ… Most commonly used in practice

### 4.6 Challenges and Solutions

**Challenge 1: Local Minima**

- Non-convex functions have multiple local minima
- Solutions: Random restarts, momentum, simulated annealing

**Challenge 2: Saddle Points**

- Points where gradient is zero but not a minimum
- Solutions: Second-order methods, momentum

**Challenge 3: Plateaus**

- Flat regions with very small gradients
- Solutions: Adaptive learning rates, patience

**Challenge 4: Ill-conditioned Problems**

- Different dimensions have different scales
- Solutions: Feature normalization, preconditioning

### 4.7 Advanced Optimization Algorithms

**Momentum:**

- vâ‚œâ‚Šâ‚ = Î²Â·vâ‚œ + âˆ‡f(xâ‚œ)
- xâ‚œâ‚Šâ‚ = xâ‚œ - Î±Â·vâ‚œâ‚Šâ‚
- Accumulates velocity, smooths updates

**Nesterov Accelerated Gradient:**

- "Look ahead" before computing gradient
- Often converges faster than standard momentum

**AdaGrad:**

- Adapts learning rate per parameter
- Suitable for sparse data

**RMSprop:**

- Uses moving average of squared gradients
- Works well for non-stationary problems

**Adam (Adaptive Moment Estimation):**

- Combines momentum and RMSprop
- Most popular in deep learning
- Automatically adapts learning rates

---

## 5. Convexity and Optimization Landscape

### 5.1 Convex Functions

**Definition:** f is convex if for any xâ‚, xâ‚‚ and Î» âˆˆ [0,1]:
**f(Î»xâ‚ + (1-Î»)xâ‚‚) â‰¤ Î»f(xâ‚) + (1-Î»)f(xâ‚‚)**

**Properties:**

- Any local minimum is a global minimum
- Gradient descent guaranteed to find global minimum
- Examples: Linear regression, logistic regression

**Convex Optimization:**

- Well-studied, efficient algorithms
- Strong convergence guarantees
- Practical and theoretical importance

### 5.2 Non-Convex Optimization

**Deep Learning Challenge:**

- Neural networks have non-convex loss functions
- Multiple local minima and saddle points
- No guarantee of finding global minimum

**Why It Works Anyway:**

- Many local minima are "good enough"
- Over-parameterization helps (wide networks)
- Stochastic gradient descent provides regularization
- Modern architectures designed for trainability

---

## 6. Exercise: Gradient Descent Implementation

**Objective:** Implement gradient descent from scratch to minimize a function.

**Problem:** Minimize f(x, y) = xÂ² + yÂ²

**Steps:**

1. Define the objective function: f(x, y) = xÂ² + yÂ²
2. Compute gradient: âˆ‡f = [2x, 2y]
3. Initialize starting point (e.g., xâ‚€ = [5, 5])
4. Set learning rate (e.g., Î± = 0.1)
5. Iteratively update: [x, y]â‚œâ‚Šâ‚ = [x, y]â‚œ - Î±Â·[2x, 2y]â‚œ
6. Track progress until convergence
7. Verify: Should converge to [0, 0] where f(0,0) = 0

**Expected Behavior:**

- Function value should decrease monotonically
- Position should spiral toward origin
- Convergence depends on learning rate choice

**Analysis:**

- Try different learning rates: 0.01, 0.1, 0.5, 0.9
- Observe convergence speed and stability
- Plot optimization path on contour map

---

## 7. Best Practices for Mathematical ML

### 7.1 Numerical Stability

**Common Issues:**

1. **Overflow:** Numbers become too large
2. **Underflow:** Numbers become too small
3. **Loss of precision:** Subtraction of similar numbers

**Solutions:**

- Log-space computations for small probabilities
- Numerical tricks (log-sum-exp)
- Careful ordering of operations
- Use of numerically stable formulas

### 7.2 Computational Efficiency

**Vectorization:**

- Replace loops with matrix operations
- 10-100x speedup typical
- Leverages optimized linear algebra libraries

**Broadcasting:**

- Implicit expansion of dimensions
- Avoids explicit loops and copies

**Memory Management:**

- In-place operations when possible
- Clear intermediate results
- Batch processing for large datasets

### 7.3 Debugging Mathematical Code

**Verification Strategies:**

1. **Gradient Checking:** Compare analytical vs numerical gradients
2. **Dimensionality Checking:** Verify matrix shapes
3. **Simple Test Cases:** Known solutions
4. **Visualization:** Plot intermediate results
5. **Unit Tests:** Test individual components

---

## 8. Next Steps

Congratulations! You've built a solid mathematical foundation for machine learning. You now understand:

- **Linear Algebra:** Vectors, matrices, eigenvalues, transformations
- **Calculus:** Derivatives, gradients, optimization theory
- **Probability & Statistics:** Distributions, correlation, statistical measures
- **Gradient Descent:** The core optimization algorithm powering ML

**Coming Up Next:**

- Day 8-10: Introduction to Machine Learning
- Scikit-learn fundamentals
- Classification and regression models
- Model evaluation and validation

---

## Additional Resources

### Linear Algebra

- **3Blue1Brown: Essence of Linear Algebra** - Visual, intuitive explanations
- **MIT OpenCourseWare: Linear Algebra** - Rigorous treatment by Gilbert Strang
- **Khan Academy: Linear Algebra** - Step-by-step tutorials

### Calculus

- **Khan Academy: Multivariable Calculus** - Comprehensive coverage
- **3Blue1Brown: Essence of Calculus** - Beautiful visualizations
- **MIT OpenCourseWare: Multivariable Calculus** - Advanced topics

### Probability & Statistics

- **Seeing Theory** - Interactive visual introduction to probability
- **StatQuest with Josh Starmer** - Fun, clear explanations
- **Khan Academy: Statistics and Probability** - Complete course

### Optimization

- **Convex Optimization** by Boyd & Vandenberghe - Free online textbook
- **Numerical Optimization** by Nocedal & Wright - Advanced reference

### Books

- **Mathematics for Machine Learning** by Deisenroth, Faisal, and Ong
  - Free PDF available online
  - Covers all topics needed for ML
- **Deep Learning** by Goodfellow, Bengio, and Courville

  - Chapters 2-4: Mathematical foundations
  - Free online version available

- **Pattern Recognition and Machine Learning** by Bishop
  - Comprehensive probabilistic perspective

### Practice

- **Brilliant.org** - Interactive problem-solving
- **Khan Academy** - Structured practice problems
- **MIT OCW Problem Sets** - Challenging exercises

---

**Keep Calculating! ğŸ“âœ¨**
